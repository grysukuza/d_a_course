# Glossary

| Term                                                                     | Definition                                                                                                                                                                                                                                                                 |
| ------------------------------------------------------------------------ | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| Accuracy                                                                 | A metric that measures the percentage of correctly classified instances in a dataset.                                                                                                                                                                                      |
| Activation Layer                                                         | A layer in neural networks that applies an activation function to introduce non-linearity into the model.                                                                                                                                                                  |
| Adam Optimizer                                                           | An optimization algorithm that combines the advantages of AdaGrad and RMSProp, using adaptive learning rates for faster convergence.                                                                                                                                       |
| Adaptive Models                                                          | Models that can adjust their parameters or structure in response to changes in data patterns or distributions.                                                                                                                                                             |
| Adaptor modules                                                          | Additional layers or components added to pre-trained models to facilitate fine-tuning on specific tasks without altering the original model's parameters extensively.                                                                                                      |
| Amazon Machine Image (AMI)                                               | A template that contains the software configuration (OS, application server, applications) required to launch an instance on AWS EC2.                                                                                                                                      |
| Amazon SageMaker                                                         | A fully managed service that provides tools for building, training, and deploying machine learning models on AWS.                                                                                                                                                          |
| Amazon Web Services Elastic Compute Cloud Instance (AWS EC2)             | A virtual server in the AWS cloud that provides scalable computing capacity.                                                                                                                                                                                               |
| Ambiguity                                                                | In machine learning, this refers to uncertainty or multiple possible interpretations of a data point or model output.                                                                                                                                                      |
| Anaconda (Conda)                                                         | A distribution of the Python and R programming languages for scientific computing that aims to simplify package management and deployment.                                                                                                                                 |
| Annotations                                                              | Metadata added to data, often used to label or provide additional information about the data.                                                                                                                                                                              |
| Anomaly Score                                                            | A value indicating the degree to which a data point deviates from normal or expected behavior.                                                                                                                                                                             |
| Attention Head                                                           | A component of the attention mechanism in transformers that focuses on different parts of the input sequence.                                                                                                                                                              |
| Attention Matrix                                                         | A matrix that contains attention scores, representing the importance of one token in a sequence to another in the same sequence.                                                                                                                                           |
| Attention-Weighted Value Vector                                          | A vector in attention mechanisms obtained by weighting the value vectors by the attention scores.                                                                                                                                                                          |
| Autoencoders                                                             | Neural networks used for unsupervised learning to encode input data into a lower-dimensional representation and decode it back to the original form.                                                                                                                       |
| Backpropagation                                                          | A training algorithm for neural networks that computes gradients of the loss function with respect to each weight by the chain rule.                                                                                                                                       |
| Balancing (Datasets)                                                     | The process of adjusting the dataset to ensure each class is equally represented to prevent bias during training.                                                                                                                                                          |
| Batch (Training)                                                         | A subset of the training dataset used to update model weights in one iteration during training.                                                                                                                                                                            |
| Benchmarks                                                               | Standardized datasets and tasks used to evaluate and compare the performance of machine learning models.                                                                                                                                                                   |
| Biases                                                                   | Parameters in a model that allow it to fit the data better by providing an offset to the weighted sum of inputs.                                                                                                                                                           |
| Bidirectional Encoder Representations from Transformers (BERT) / ROBERTA | Pre-trained transformer models designed for natural language understanding tasks, with ROBERTA being a robustly optimized variant of BERT.                                                                                                                                 |
| Binary Classification                                                    | A type of classification task where the model predicts one of two possible classes.                                                                                                                                                                                        |
| Bitfit                                                                   | A lightweight parameter-efficient fine-tuning method for pre-trained models where only the bias terms of the model are updated during training.                                                                                                                            |
| Bottleneck (as in Autoencoders)                                          | The central, often smaller, layer of an autoencoder that represents the compressed knowledge of the input data.                                                                                                                                                            |
| Centroid                                                                 | The center of a cluster, often calculated as the mean of all data points in the cluster.                                                                                                                                                                                   |
| ChromaDB                                                                 | A specialized database optimized for storing and querying chromatic information or features from images.                                                                                                                                                                   |
| Chunking                                                                 | The process of dividing data into smaller, more manageable pieces or chunks, often used in text processing.                                                                                                                                                                |
| Classification                                                           | The task of predicting the category or class of a given data point.                                                                                                                                                                                                        |
| classification_report                                                    | A report in machine learning that shows the precision, recall, and F1 score of a classification model.                                                                                                                                                                     |
| Clustering                                                               | The task of grouping a set of objects in such a way that objects in the same group are more similar to each other than to those in other groups.                                                                                                                           |
| Completions                                                              | Predictions made by language models that continue or complete a given text prompt.                                                                                                                                                                                         |
| Compute Unified Device Architecture (CUDA)                               | A parallel computing platform and application programming interface (API) model created by Nvidia, enabling general-purpose computing on GPUs.                                                                                                                             |
| Concept Drift                                                            | The phenomenon where the statistical properties of the target variable change over time in unforeseen ways.                                                                                                                                                                |
| Confusion Matrices                                                       | A table used to describe the performance of a classification model, showing the true positives, false positives, true negatives, and false negatives.                                                                                                                      |
| Context Window                                                           | The portion of input data used by a model to make predictions, particularly in sequence-based models.                                                                                                                                                                      |
| Context-Free Value Vector                                                | A vector representing the value of an input token without considering the surrounding context.                                                                                                                                                                             |
| Context-Weighted Value Vector                                            | A vector representing the value of an input token after applying attention weights based on its context.                                                                                                                                                                   |
| Contrastive Language-Image Pretraining Model (CLIP)                      | A model that learns visual concepts from natural language supervision, enabling zero-shot transfer to various vision tasks.                                                                                                                                                |
| Convolutional Layers (Like Conv2d)                                       | Layers in neural networks that apply convolution operations to the input data, commonly used in image processing.                                                                                                                                                          |
| Corpus                                                                   | A large and structured set of texts used for training and evaluating language models.                                                                                                                                                                                      |
| Cosine Distance                                                          | A measure of similarity between two non-zero vectors that calculates the cosine of the angle between them.                                                                                                                                                                 |
| Cost Function                                                            | A function that measures the error or difference between the predicted and actual values, guiding the optimization process.                                                                                                                                                |
| Criterion                                                                | A function or rule used to evaluate the performance of a machine learning model, often synonymous with a loss function.                                                                                                                                                    |
| Cross-Entropy Loss                                                       | A loss function commonly used in classification tasks, measuring the difference between the predicted probability distribution and the true distribution.                                                                                                                  |
| Cross-Validation                                                         | A technique for assessing how a model generalizes to an independent dataset by partitioning the data into training and validation sets multiple times.                                                                                                                     |
| Data Drift                                                               | The change in the distribution of data over time, which can affect model performance.                                                                                                                                                                                      |
| DataLoader                                                               | A PyTorch class that provides an efficient way to iterate over a dataset, supporting batching, shuffling, and parallel data loading.                                                                                                                                       |
| Davies-Bouldin Index (DBI)                                               | A metric for evaluating clustering algorithms by measuring the average similarity ratio of each cluster with its most similar cluster.                                                                                                                                     |
| Decision Trees                                                           | A type of model used for classification and regression that splits the data into branches based on feature values to make predictions.                                                                                                                                     |
| Decoder (as in Autoencoders)                                             | The part of an autoencoder that reconstructs the input data from the encoded representation.                                                                                                                                                                               |
| Deep Learning                                                            | A subset of machine learning that uses neural networks with many layers (deep architectures) to model complex patterns in data.                                                                                                                                            |
| Density-Based Spatial Clustering of Applications with Noise (DBSCAN)     | A clustering algorithm that groups points that are closely packed together while marking points in low-density regions as outliers.                                                                                                                                        |
| Device Type (CPU / GPU / MPS / CUDA)                                     | Different types of hardware used for executing machine learning models, where CPU is a central processing unit, GPU is a graphics processing unit, MPS refers to Metal Performance Shaders on Apple devices, and CUDA is a parallel computing platform for GPUs by Nvidia. |
| Diff Pruning                                                             | A technique for reducing the size of pre-trained models by pruning parameters that have minimal impact on performance, based on their importance scores.                                                                                                                   |
| Dimensionality Reduction                                                 | Techniques for reducing the number of features or dimensions in a dataset while preserving as much information as possible.                                                                                                                                                |
| Distance Measure                                                         | A metric used to quantify the similarity or dissimilarity between two data points, such as Euclidean distance or cosine distance.                                                                                                                                          |
| Docker                                                                   | A platform that enables the creation, deployment, and running of applications in containers, which are lightweight, portable, and self-sufficient environments.                                                                                                            |
| Dot-Product Similarity                                                   | A measure of similarity between two vectors calculated by the dot product of the vectors, often used in attention mechanisms.                                                                                                                                              |
| Drift Detection Algorithms                                               | Algorithms designed to detect changes in the data distribution or model performance over time.                                                                                                                                                                             |
| Dropout Layers                                                           | Layers in neural networks that randomly set a fraction of input units to zero during training to prevent overfitting.                                                                                                                                                      |
| Dunn Index                                                               | A metric used to evaluate clustering algorithms, considering the ratio of the minimum inter-cluster distance to the maximum intra-cluster distance.                                                                                                                        |
| Early Stopping Rounds                                                    | A technique used to prevent overfitting in training by stopping the training process if the model performance on the validation set does not improve for a specified number of rounds.                                                                                     |
| Elbow Method                                                             | A technique used in clustering to determine the optimal number of clusters by plotting the explained variance as a function of the number of clusters and looking for an "elbow" point.                                                                                    |
| Embeddings                                                               | Dense vector representations of data, such as words or images, that capture the semantic meaning and relationships in a lower-dimensional space.                                                                                                                           |
| Encoder (as in Autoencoders)                                             | The part of an autoencoder that compresses the input data into a lower-dimensional representation.                                                                                                                                                                         |
| Ensemble Model                                                           | A model that combines the predictions of multiple individual models to improve overall performance and robustness.                                                                                                                                                         |
| Epochs                                                                   | Complete passes through the entire training dataset during the training process of a machine learning model.                                                                                                                                                               |
| Euclidean Distance                                                       | A measure of the straight-line distance between two points in Euclidean space.                                                                                                                                                                                             |
| Evaluation                                                               | The process of assessing the performance of a machine learning model on a test dataset using various metrics.                                                                                                                                                              |
| Evaluation Metrics                                                       | Metrics used to quantify the performance of a machine learning model, such as accuracy, precision, recall, and F1 score.                                                                                                                                                   |
| eXtreme Gradient Boosting (XGBoost)                                      | An efficient and scalable implementation of gradient boosting algorithms, widely used for regression and classification tasks.                                                                                                                                             |
| F-Score                                                                  | A metric that combines precision and recall into a single score, considering both false positives and false negatives.                                                                                                                                                     |
| F1 Score                                                                 | The harmonic mean of precision and recall, providing a single metric that balances both aspects of model performance.                                                                                                                                                      |
| Feature Engineering                                                      | The process of selecting, transforming, and creating new features from raw data to improve model performance.                                                                                                                                                              |
| Feature Scaling                                                          | Techniques such as normalization and standardization used to adjust the scale of features to ensure they contribute equally to the model.                                                                                                                                  |
| Feature Selection                                                        | The process of selecting a subset of relevant features for use in model training to reduce dimensionality and improve performance.                                                                                                                                         |
| Feature Space                                                            | The multi-dimensional space defined by the features used in a machine learning model.                                                                                                                                                                                      |
| Feature Standardization                                                  | A type of feature scaling that transforms features to have zero mean and unit variance.                                                                                                                                                                                    |
| Features                                                                 | Individual measurable properties or characteristics of the data used as input to a machine learning model.                                                                                                                                                                 |
| Fine-Tuning                                                              | The process of further training a pre-trained model on a new dataset to adapt it to a specific task or domain.                                                                                                                                                             |
| Flask (Server)                                                           | A lightweight web framework for Python that allows the development of web applications and APIs.                                                                                                                                                                           |
| Flatten                                                                  | A layer in neural networks that reshapes multi-dimensional input data into a one-dimensional vector.                                                                                                                                                                       |
| Forward                                                                  | The forward pass in neural networks where input data is passed through the network layers to obtain predictions.                                                                                                                                                           |
| Fraud Detection                                                          | The application of machine learning techniques to identify and prevent fraudulent activities in various domains.                                                                                                                                                           |
| Freeze Parameters                                                        | The process of preventing certain model parameters from being updated during training to retain pre-learned knowledge.                                                                                                                                                     |
| Fully Connected Layers                                                   | Layers in neural networks where each neuron is connected to every neuron in the previous layer, also known as dense layers.                                                                                                                                                |
| Gaussian Mixture Models (GMM)                                            | A probabilistic model that assumes all data points are generated from a mixture of several Gaussian distributions with unknown parameters.                                                                                                                                 |
| Generative Adversarial Networks (GANs)                                   | A class of neural networks consisting of a generator and a discriminator that compete against each other to generate realistic data samples.                                                                                                                               |
| Generative Artificial Intelligence (AI)                                  | AI systems that generate new content, such as text, images, or music, based on learned patterns from training data.                                                                                                                                                        |
| Generative Pre-trained Transformer (GPT)                                 | A type of transformer model pre-trained on a large corpus of text data to generate coherent and contextually relevant text.                                                                                                                                                |
| Google Colaboratory (Colab)                                              | A free cloud service that allows users to write and execute Python code in a Jupyter notebook environment, often used for machine learning.                                                                                                                                |
| Gradient Boosted Trees                                                   | An ensemble learning method that builds multiple decision trees sequentially, with each tree correcting the errors of its predecessor.                                                                                                                                     |
| Gradient Descent                                                         | An optimization algorithm used to minimize the loss function by iteratively updating model parameters in the direction of the steepest descent.                                                                                                                            |
| Grid Search                                                              | A hyperparameter tuning technique that exhaustively searches through a specified parameter grid to find the best model configuration.                                                                                                                                      |
| Hallucinations                                                           | In language models, these are generated outputs that are fluent but factually incorrect or nonsensical.                                                                                                                                                                    |
| Heuristic-Based Classifier                                               | A classifier that makes predictions based on a set of heuristic rules rather than learned patterns from data.                                                                                                                                                              |
| Hierarchical Clustering                                                  | A clustering method that builds a hierarchy of clusters by either merging smaller clusters into larger ones (agglomerative) or splitting larger clusters into smaller ones (divisive).                                                                                     |
| Hierarchical Navigable Small World (HNSW)                                | An algorithm for efficient approximate nearest neighbor search in high-dimensional spaces.                                                                                                                                                                                 |
| High-Dimensional Space                                                   | A space with a large number of dimensions or features, often leading to the curse of dimensionality in machine learning.                                                                                                                                                   |
| Hyperbolic Tangent (Tanh)                                                | An activation function that maps input values to a range between -1 and 1, often used in neural networks.                                                                                                                                                                  |
| Hyperparameter Tuning                                                    | The process of optimizing hyperparameters, which are parameters set before the learning process begins, to improve model performance.                                                                                                                                      |
| Hyperparameters                                                          | Parameters set before training a machine learning model that control the learning process, such as learning rate, batch size, and the number of layers.                                                                                                                    |
| Hyperplane                                                               | A decision boundary in a high-dimensional space that separates different classes in classification tasks.                                                                                                                                                                  |
| Image Segmentation                                                       | The task of partitioning an image into meaningful regions or segments, often used in computer vision.                                                                                                                                                                      |
| ImageNet Dataset                                                         | A large-scale dataset of annotated images used for training and evaluating computer vision models.                                                                                                                                                                         |
| In-Painting                                                              | The process of filling in missing or corrupted parts of an image using machine learning techniques.                                                                                                                                                                        |
| index_to_name JSON File                                                  | A JSON file mapping index values to class names or labels, often used in classification tasks.                                                                                                                                                                             |
| Inertia                                                                  | A measure of how well the data points are clustered around the centroids in a clustering algorithm, with lower values indicating better clustering.                                                                                                                        |
| Inference                                                                | The process of making predictions using a trained machine learning model.                                                                                                                                                                                                  |
| Inference Server                                                         | A server that hosts machine learning models and provides APIs for making predictions on new data.                                                                                                                                                                          |
| Inverse Mapping                                                          | The process of mapping data back from a lower-dimensional representation to its original form, often used in dimensionality reduction techniques.                                                                                                                          |
| Isolation Forest                                                         | An anomaly detection algorithm that isolates observations by randomly selecting a feature and then randomly selecting a split value between the maximum and minimum values of the selected feature.                                                                        |
| K-Means                                                                  | A popular clustering algorithm that partitions data into K clusters by minimizing the variance within each cluster.                                                                                                                                                        |
| K-Nearest Neighbors (KNN)                                                | A simple, non-parametric algorithm that classifies data points based on the labels of their K nearest neighbors.                                                                                                                                                           |
| Kernel                                                                   | A function used in machine learning algorithms, such as support vector machines, to transform data into a higher-dimensional space.                                                                                                                                        |
| Kernel Trick                                                             | A technique that allows algorithms to operate in a high-dimensional space without explicitly computing the coordinates of the data in that space.                                                                                                                          |
| L1 Distance                                                              | A measure of distance between two points, calculated as the sum of the absolute differences between their coordinates.                                                                                                                                                     |
| L2 Distance                                                              | A measure of distance between two points, calculated as the square root of the sum of the squared differences between their coordinates.                                                                                                                                   |
| Labels                                                                   | The target values or categories assigned to data points in supervised learning tasks.                                                                                                                                                                                      |
| Large Language Model (LLM)                                               | A type of AI model, such as GPT, that is trained on vast amounts of text data to understand and generate human-like language.                                                                                                                                              |
| Learning Curves                                                          | Plots that show the performance of a machine learning model over time or as a function of the number of training samples.                                                                                                                                                  |
| Learning Rate                                                            | A hyperparameter that controls the step size at each iteration of the optimization algorithm during training.                                                                                                                                                              |
| Linear Layers                                                            | Layers in neural networks that apply a linear transformation to the input data, often followed by an activation function.                                                                                                                                                  |
| Linear Regression                                                        | A regression algorithm that models the relationship between a dependent variable and one or more independent variables using a linear equation.                                                                                                                            |
| Local Outlier Factor (LOF)                                               | An algorithm for identifying anomalies in data based on the local density deviation of a data point with respect to its neighbors.                                                                                                                                         |
| Log Loss                                                                 | A loss function used in classification tasks that measures the performance of a model by comparing the predicted probability distribution to the actual distribution.                                                                                                      |
| Logistic Regression                                                      | A classification algorithm that models the probability of a binary outcome using a logistic function.                                                                                                                                                                      |
| Logits                                                                   | The raw, unnormalized scores outputted by a model before applying an activation function like softmax.                                                                                                                                                                     |
| Long Short-Term Memory (LSTM)                                            | A type of recurrent neural network (RNN) designed to capture long-term dependencies in sequential data.                                                                                                                                                                    |
| Lookback Window Size                                                     | The number of previous time steps considered by a model when making predictions in time series forecasting.                                                                                                                                                                |
| Loss Function                                                            | A function that measures the difference between the predicted and actual values, guiding the optimization process during training.                                                                                                                                         |
| Low Rank Adaptation (LoRA)                                               | A technique for adapting pre-trained models to new tasks by approximating weight matrices with lower-rank decompositions.                                                                                                                                                  |
| Machine Learning (ML)                                                    | A field of artificial intelligence that uses algorithms and statistical models to enable computers to learn from and make predictions based on data.                                                                                                                       |
| Machine Learning Models (ML Models)                                      | Mathematical models built using machine learning algorithms to make predictions or decisions based on input data.                                                                                                                                                          |
| Machine Learning Paradigm (ML Paradigm)                                  | The overarching framework or approach used to solve machine learning problems, such as supervised, unsupervised, or reinforcement learning.                                                                                                                                |
| Majority Voting                                                          | An ensemble method that combines the predictions of multiple models by taking the most common prediction as the final output.                                                                                                                                              |
| Manifold Learning                                                        | Techniques for reducing dimensionality by assuming that the data lies on a lower-dimensional manifold within the higher-dimensional space.                                                                                                                                 |
| Matplotlib                                                               | A Python library for creating static, animated, and interactive visualizations in data analysis and machine learning.                                                                                                                                                      |
| Mean Absolute Error                                                      | A regression metric that measures the average absolute difference between predicted and actual values.                                                                                                                                                                     |
| Mean-Shift Clustering                                                    | A clustering algorithm that assigns data points to clusters by shifting points towards the mode of the data density.                                                                                                                                                       |
| Metal Performance Shaders (MPS)                                          | A framework by Apple for accelerating graphics and computation tasks on macOS and iOS devices.                                                                                                                                                                             |
| Metrics Logging                                                          | The practice of recording and tracking performance metrics of machine learning models during training and evaluation.                                                                                                                                                      |
| min_child_weight                                                         | A hyperparameter in gradient boosting algorithms that controls the minimum sum of instance weight needed in a child node to make a split.                                                                                                                                  |
| Model                                                                    | An abstraction in machine learning that encapsulates the learned patterns from the training data to make predictions on new data.                                                                                                                                          |
| Model Fit                                                                | The process of training a machine learning model on a dataset to learn the patterns and relationships within the data.                                                                                                                                                     |
| Model Packaging                                                          | The process of preparing a trained machine learning model for deployment, including saving the model and its dependencies in a portable format.                                                                                                                            |
| Modified National Institute of Standards and Technology Database (MNIST) | A widely-used dataset of handwritten digits for training and testing machine learning models.                                                                                                                                                                              |
| Multi-Class Classification                                               | A classification task where the model predicts one of three or more possible classes.                                                                                                                                                                                      |
| Multinomial Logistic Regression                                          | An extension of logistic regression for multi-class classification problems.                                                                                                                                                                                               |
| Multiple Regression                                                      | A regression analysis technique that models the relationship between a dependent variable and multiple independent variables.                                                                                                                                              |
| n_estimators                                                             | A hyperparameter in ensemble learning algorithms like random forests and gradient boosting that specifies the number of trees or models to be created.                                                                                                                     |
| Natural Language Processing (NLP)                                        | A field of artificial intelligence that focuses on the interaction between computers and human language, enabling computers to understand, interpret, and generate text.                                                                                                   |
| Negative Mean Absolute Error (neg_mean_absolute_error)                   | A metric used to evaluate regression models, representing the negative of the mean absolute error to facilitate certain optimization frameworks.                                                                                                                           |
| Neural Network / Multilayer Perceptron (MLP)                             | A type of artificial neural network with multiple layers of neurons that can learn complex patterns in data.                                                                                                                                                               |
| nn.Module                                                                | A base class for all neural network modules in PyTorch, providing a way to define and organize model architectures.                                                                                                                                                        |
| nn.Sequential                                                            | A container module in PyTorch that allows the construction of a model by stacking multiple layers sequentially.                                                                                                                                                            |
| Non-Linear Transform                                                     | Transformations that introduce non-linearity into a model, allowing it to learn more complex patterns in the data.                                                                                                                                                         |
| Normalization                                                            | The process of scaling data to a standard range or distribution, often to improve the performance and training stability of machine learning models.                                                                                                                       |
| Normalized Mutual Information (NMI)                                      | A metric for evaluating the similarity between two clustering results, normalized to account for chance agreements.                                                                                                                                                        |
| Novelty Detection                                                        | The task of identifying new or unusual data points that do not conform to the patterns seen in the training data.                                                                                                                                                          |
| One-Class Support Vector Machine (SVM)                                   | A type of SVM used for anomaly detection, trained on data from a single class to identify outliers.                                                                                                                                                                        |
| One-Hot Encoding                                                         | A technique for representing categorical data as binary vectors, where each category is represented by a vector with a single high (value and the rest low (0) values.                                                                                                     |
| One-vs-Rest (OvR)                                                        | A strategy for multi-class classification that involves training a separate binary classifier for each class against all other classes.                                                                                                                                    |
| Optimizer                                                                | An algorithm used to adjust the model parameters during training to minimize the loss function.                                                                                                                                                                            |
| Orthogonality                                                            | The concept of two vectors being perpendicular to each other, often used to describe features that are uncorrelated or independent.                                                                                                                                        |
| Overfitting                                                              | A situation where a machine learning model performs well on the training data but fails to generalize to new, unseen data.                                                                                                                                                 |
| Padding (Convolutions)                                                   | The process of adding extra pixels around the border of an image or feature map before applying a convolution operation to control the spatial dimensions of the output.                                                                                                   |
| Pandas                                                                   | A Python library for data manipulation and analysis, providing data structures like DataFrame and Series.                                                                                                                                                                  |
| Parameters                                                               | The internal variables of a machine learning model that are learned from the training data, such as weights and biases.                                                                                                                                                    |
| Perplexity                                                               | A measure of how well a probabilistic model predicts a sample, often used in evaluating language models.                                                                                                                                                                   |
| pgvector                                                                 | An extension for PostgreSQL that adds support for storing and querying high-dimensional vectors, enabling similarity search and other vector-based operations.                                                                                                             |
| Pipeline                                                                 | A series of data processing and modeling steps arranged in sequence, often used to streamline machine learning workflows.                                                                                                                                                  |
| Pipenv                                                                   | A tool for managing Python package dependencies and virtual environments.                                                                                                                                                                                                  |
| Pooling Layers                                                           | Layers in neural networks that downsample the input by summarizing the presence of features in patches, commonly used in convolutional networks.                                                                                                                           |
| Pre-Trained Models                                                       | Models that have been previously trained on large datasets and can be fine-tuned or used as-is for specific tasks.                                                                                                                                                         |
| Precision                                                                | A metric that measures the proportion of true positive predictions among all positive predictions made by the model.                                                                                                                                                       |
| Prediction                                                               | The output or result generated by a machine learning model when provided with input data.                                                                                                                                                                                  |
| Preprocessing                                                            | The process of transforming raw data into a suitable format for model training, often involving steps like normalization, feature extraction, and data cleaning.                                                                                                           |
| Principal Component Analysis (PCA)                                       | A dimensionality reduction technique that transforms data into a set of orthogonal components, capturing the most variance in the data.                                                                                                                                    |
| Probability Distribution                                                 | A mathematical function that describes the likelihood of different outcomes in a random experiment.                                                                                                                                                                        |
| Prompt                                                                   | An input text provided to a language model to generate a continuation or response.                                                                                                                                                                                         |
| pt File / pth File                                                       | A file format used by PyTorch to save model weights, parameters, and training progress.                                                                                                                                                                                    |
| PyTorch                                                                  | An open-source machine learning library for Python, providing tools for building and training neural networks.                                                                                                                                                             |
| Q-Learning                                                               | A model-free reinforcement learning algorithm that learns the value of an action in a particular state by updating Q-values based on the received reward and the estimated future rewards.                                                                                 |
| QLoRA                                                                    | Quantized Low-Rank Adaptation, a method that combines quantization and low-rank adaptation techniques to make model fine-tuning more efficient in terms of memory and computational resources.                                                                             |
| Quantization                                                             | The process of reducing the precision of the numbers used to represent a model's parameters, often to improve efficiency and reduce memory usage.                                                                                                                          |
| Query (Transformers)                                                     | In the attention mechanism of transformer models, the query is a vector used to match with key vectors to compute attention scores.                                                                                                                                        |
| Rand Index (RI)                                                          | A measure of the similarity between two data clusterings, considering all pairs of samples and counting pairs that are assigned to the same or different clusters in both clusterings.                                                                                     |
| Random Forests                                                           | An ensemble learning method that constructs multiple decision trees and combines their predictions to improve accuracy and control overfitting.                                                                                                                            |
| Random Sampling (Variational Autoencoders) (VAE)                         | A technique in VAEs where the latent space is sampled from a continuous distribution, typically Gaussian, to generate new data points.                                                                                                                                     |
| random_split                                                             | A function in PyTorch that splits a dataset into non-overlapping new datasets of given lengths.                                                                                                                                                                            |
| Recall                                                                   | A metric that measures the proportion of true positive predictions among all actual positive instances in the dataset.                                                                                                                                                     |
| Reconstruction Loss                                                      | The loss calculated by comparing the original input to its reconstruction, often used in autoencoders.                                                                                                                                                                     |
| Rectified Linear Units (ReLUs)                                           | An activation function used in neural networks that outputs the input directly if it is positive, otherwise, it outputs zero.                                                                                                                                              |
| Regression                                                               | A type of machine learning task where the goal is to predict a continuous target variable based on input features.                                                                                                                                                         |
| Regularization                                                           | Techniques used to prevent overfitting by penalizing overly complex models, such as L1 and L2 regularization.                                                                                                                                                              |
| Reinforcement Learning                                                   | A type of machine learning where an agent learns to make decisions by taking actions in an environment to maximize cumulative rewards through trial and error.                                                                                                             |
| Reshape (np.reshape)                                                     | A NumPy function that changes the shape of an array without changing its data.                                                                                                                                                                                             |
| Retrieval Augmented Generation (RAG)                                     | A model architecture that combines retrieval-based methods with generation-based models to produce more accurate and contextually relevant outputs.                                                                                                                        |
| Riemannian Geometry                                                      | A branch of differential geometry that studies curved spaces, often used in advanced machine learning techniques involving manifolds.                                                                                                                                      |
| Scaled Dot-Product Attention                                             | A mechanism in transformers that computes attention scores using the dot product of query and key vectors, scaled by the square root of the dimension of the key vectors.                                                                                                  |
| SciKit-Learn                                                             | A Python library for machine learning that provides simple and efficient tools for data mining and data analysis.                                                                                                                                                          |
| Self-Supervised Learning                                                 | A type of unsupervised learning where the model learns from the data itself by predicting part of the input from other parts.                                                                                                                                              |
| Semantic Embedding Model                                                 | A model that generates vector representations of data (e.g., text, images) that capture their semantic meaning.                                                                                                                                                            |
| Semantic Search                                                          | A search technique that uses embeddings to find semantically similar results rather than relying on exact keyword matches.                                                                                                                                                 |
| Semi-Supervised Learning                                                 | A machine learning approach that uses both labeled and unlabeled data to improve learning accuracy.                                                                                                                                                                        |
| Sentiment Analysis                                                       | The task of determining the sentiment or emotional tone of a piece of text, such as positive, negative, or neutral.                                                                                                                                                        |
| Shallow Learning                                                         | Machine learning models that have a limited number of layers or complexity, such as logistic regression or support vector machines.                                                                                                                                        |
| Sigmoid                                                                  | An activation function that maps input values to a range between 0 and 1, often used in binary classification problems.                                                                                                                                                    |
| Silhouette Score                                                         | A metric used to evaluate the quality of clusters by measuring the similarity of a data point to its own cluster compared to other clusters.                                                                                                                               |
| Similarity Search                                                        | The task of finding data points in a dataset that are similar to a given query point, often using vector embeddings.                                                                                                                                                       |
| Softmax                                                                  | An activation function that converts a vector of raw scores into a probability distribution over multiple classes.                                                                                                                                                         |
| Solver (e.g. LGBFS)                                                      | An optimization algorithm used for minimizing the loss function in machine learning models.                                                                                                                                                                                |
| Spectral Clustering                                                      | A clustering technique that uses the eigenvalues of the similarity matrix of the data to perform dimensionality reduction before clustering in fewer dimensions.                                                                                                           |
| State Dictionary                                                         | A dictionary object in PyTorch that maps each layer to its corresponding parameter tensor, used for saving and loading models.                                                                                                                                             |
| Stride (Convolutions)                                                    | The step size with which a convolutional filter moves across the input data, affecting the spatial dimensions of the output.                                                                                                                                               |
| Sum of Squared Distances                                                 | A measure used in clustering to quantify the total variance within each cluster, aiming to minimize this value for optimal clustering.                                                                                                                                     |
| Supervised Learning                                                      | A type of machine learning where the model is trained on labeled data, learning to predict the output from the input features.                                                                                                                                             |
| Support Vector Machines (SVM)                                            | A supervised learning algorithm used for classification and regression tasks, which finds the hyperplane that best separates different classes in the feature space.                                                                                                       |
| t-Distributed Stochastic Neighbor Embedding (t-SNE)                      | A dimensionality reduction technique used for visualizing high-dimensional data by mapping it to two or three dimensions.                                                                                                                                                  |
| Tensor                                                                   | A multi-dimensional array used in machine learning and deep learning to represent data and model parameters.                                                                                                                                                               |
| Time Series Forecasting                                                  | The task of predicting future values of a sequence based on past observations, often using models that capture temporal dependencies.                                                                                                                                      |
| Tokens (Large Language Models) (LLMs)                                    | Units of text (words, subwords, or characters) that are processed by large language models during training and inference.                                                                                                                                                  |
| train_test_split                                                         | A function in Scikit-Learn that splits a dataset into training and testing subsets for model evaluation.                                                                                                                                                                   |
| Trainable Weights                                                        | Parameters in a neural network that are updated during training to minimize the loss function.                                                                                                                                                                             |
| Training                                                                 | The process of learning the parameters of a machine learning model by optimizing the loss function using training data.                                                                                                                                                    |
| Training Loop                                                            | The iterative process in model training where the model parameters are updated based on the loss calculated from the predictions on the training data.                                                                                                                     |
| Training Pipeline                                                        | A series of steps in a machine learning workflow that includes data preprocessing, model training, and evaluation.                                                                                                                                                         |
| Training, Validation, Test Sets                                          | The three subsets of a dataset used to train a model, tune hyperparameters, and evaluate final model performance, respectively.                                                                                                                                            |
| Training/Validation Data Skew                                            | A situation where the training and validation datasets have different distributions, potentially leading to poor generalization.                                                                                                                                           |
| Transfer Learning                                                        | The practice of leveraging a pre-trained model on a new task, transferring the knowledge gained from the original task to improve performance on the new one.                                                                                                              |
| Transformer Architecture                                                 | A neural network architecture that uses self-attention mechanisms to process input sequences, commonly used in natural language processing.                                                                                                                                |
| Triton Inference Server                                                  | A platform for serving machine learning models at scale, providing tools for deploying, running, and managing models in production environments.                                                                                                                           |
| Underfitting                                                             | A situation where a machine learning model is too simple to capture the underlying patterns in the data, resulting in poor performance.                                                                                                                                    |
| Uniform Manifold Approximation and Projection (UMAP)                     | A dimensionality reduction technique used for visualizing and understanding high-dimensional data.                                                                                                                                                                         |
| Unsupervised Learning                                                    | A type of machine learning where the model is trained on unlabeled data, learning to identify patterns and relationships within the data.                                                                                                                                  |
| Variance                                                                 | A measure of the spread or dispersion of a set of data points, indicating how much the values differ from the mean.                                                                                                                                                        |
| Vector                                                                   | A mathematical object representing a quantity with both magnitude and direction, used in machine learning to represent data points and features.                                                                                                                           |
| Vector Database / Vector Index (Like Pinecone, Milvus, Weaviate)         | Specialized databases optimized for storing, indexing, and querying high-dimensional vector embeddings.                                                                                                                                                                    |
| Vector Embeddings                                                        | Dense vector representations of data points that capture the semantic relationships between them in a lower-dimensional space.                                                                                                                                             |
| Vector Similarity                                                        | A measure of how similar two vectors are, often calculated using metrics like cosine similarity or dot product.                                                                                                                                                            |
| Vectorization                                                            | The process of converting data into vector form, enabling mathematical and computational operations on the data.                                                                                                                                                           |
| Weighted Dot-Product Attention                                           | An attention mechanism in transformers where the dot product of query and key vectors is weighted and used to compute attention scores.                                                                                                                                    |
| Weights                                                                  | Parameters in a neural network that are learned from the training data and used to make predictions.                                                                                                                                                                       |
| Weights and Biases (wandb)                                               | A tool for tracking and visualizing machine learning experiments, providing insights into model performance and training processes.                                                                                                                                        |
| Within-Cluster Sum of Squares (WCSS)                                     | A measure of the total variance within each cluster, used to evaluate the quality of clustering algorithms.                                                                                                                                                                |
| Word2Vec                                                                 | A neural network-based model for learning vector representations of words, capturing their semantic relationships.                                                                                                                                                         |
| zero_grad                                                                | A function in PyTorch that resets the gradients of all model parameters to zero before performing a new optimization step.                                                                                                                                                 |
