{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Feature Selection and Engineering\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`#scikit-learn` `#data-preprocessing` `#logistic-regression` `#feature-engineering`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Objectives:\n",
    ">\n",
    "> - Load and explore broken data.\n",
    "> - Understand why the broken data cannot be used for training directly.\n",
    "> - Apply minimal transformations to allow initial training.\n",
    "> - Perform additional data cleaning, feature engineering, and normalization.\n",
    "> - Compare the performance of models trained on minimally processed and fully processed data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Deep Atlas Exercise Set Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Ensure you are using the coursework Pipenv environment and kernel ([instructions](../SETUP.md))\n",
    "- [x] Apply the standard Deep Atlas environment setup process by running this cell:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Running in a Virtual environment\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "sys.path.insert(0, os.path.join('..', 'includes'))\n",
    "\n",
    "import deep_atlas\n",
    "from deep_atlas import FILL_THIS_IN\n",
    "deep_atlas.initialize_environment()\n",
    "if deep_atlas.environment == 'COLAB':\n",
    "    %pip install -q python-dotenv==1.0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸš¦ Checkpoint: Start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [ ] Run this cell to record your start time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸš€ Success! Get started...\n"
     ]
    }
   ],
   "source": [
    "deep_atlas.log_start_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] To ensure everything runs smoothly, load all the necessary libraries in this section. This includes data manipulation, machine learning, and logging libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Broken Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will begin by loading a dataset that contains issues such as missing values, incorrect data types, and potentially problematic records.\n",
    "\n",
    "- [x] Load the broken dataset and display the first few rows to examine its contents:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Data loaded successfully from assets/fitness_data.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Weight</th>\n",
       "      <th>Height</th>\n",
       "      <th>Steps per Day</th>\n",
       "      <th>Calories Burned</th>\n",
       "      <th>Exercise Minutes</th>\n",
       "      <th>Resting Heart Rate</th>\n",
       "      <th>Workout Intensity</th>\n",
       "      <th>Hours of Sleep</th>\n",
       "      <th>Sleep Quality</th>\n",
       "      <th>Stress Level</th>\n",
       "      <th>Fitness Goal Achieved</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>56.0</td>\n",
       "      <td>M</td>\n",
       "      <td>65.1</td>\n",
       "      <td>179.8</td>\n",
       "      <td>5906.0</td>\n",
       "      <td>660.5</td>\n",
       "      <td>52.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>lw</td>\n",
       "      <td>9.7</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>70.7</td>\n",
       "      <td>182.4</td>\n",
       "      <td>10272.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>hgh</td>\n",
       "      <td>7.0</td>\n",
       "      <td>Poor</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32.0</td>\n",
       "      <td>F</td>\n",
       "      <td>47.9</td>\n",
       "      <td>174.3</td>\n",
       "      <td>8070.0</td>\n",
       "      <td>861.1</td>\n",
       "      <td>46.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>med</td>\n",
       "      <td>6.4</td>\n",
       "      <td>Poor</td>\n",
       "      <td>9.0</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25.0</td>\n",
       "      <td>F</td>\n",
       "      <td>68.7</td>\n",
       "      <td>166.6</td>\n",
       "      <td>6597.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>med</td>\n",
       "      <td>8.5</td>\n",
       "      <td>Good</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>38.0</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>154.1</td>\n",
       "      <td>4771.0</td>\n",
       "      <td>670.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>73.0</td>\n",
       "      <td>lw</td>\n",
       "      <td>6.7</td>\n",
       "      <td>Poor</td>\n",
       "      <td>5.0</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age Gender  Weight  Height  Steps per Day  Calories Burned  \\\n",
       "0  56.0      M    65.1   179.8         5906.0            660.5   \n",
       "1   NaN      M    70.7   182.4        10272.0              NaN   \n",
       "2  32.0      F    47.9   174.3         8070.0            861.1   \n",
       "3  25.0      F    68.7   166.6         6597.0              NaN   \n",
       "4  38.0      M     NaN   154.1         4771.0            670.2   \n",
       "\n",
       "   Exercise Minutes  Resting Heart Rate Workout Intensity  Hours of Sleep  \\\n",
       "0              52.0                65.0                lw             9.7   \n",
       "1              39.0                71.0               hgh             7.0   \n",
       "2              46.0                76.0               med             6.4   \n",
       "3              58.0                60.0               med             8.5   \n",
       "4               NaN                73.0                lw             6.7   \n",
       "\n",
       "  Sleep Quality  Stress Level Fitness Goal Achieved  \n",
       "0          Good           5.0                    No  \n",
       "1          Poor           5.0                   Yes  \n",
       "2          Poor           9.0                   Yes  \n",
       "3          Good           5.0                    No  \n",
       "4          Poor           5.0                    No  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "\n",
    "def load_data(file_path):\n",
    "    try:\n",
    "        data = pd.read_csv(file_path)\n",
    "        logging.info(f\"Data loaded successfully from {file_path}\")\n",
    "        return data\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "        raise\n",
    "    except pd.errors.EmptyDataError:\n",
    "        logging.error(f\"Empty CSV file: {file_path}\")\n",
    "        raise\n",
    "    except pd.errors.ParserError:\n",
    "        logging.error(f\"Error parsing CSV file: {file_path}\")\n",
    "        raise\n",
    "\n",
    "\n",
    "data = load_data(\"assets/fitness_data.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Broken Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will explore the dataset to identify any problems, such as missing values, incorrect data types, and duplicate records.\n",
    "\n",
    "- [x] Explore the dataset by running the following code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:Exploring data:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Age Gender  Weight  Height  Steps per Day  Calories Burned  \\\n",
      "0  56.0      M    65.1   179.8         5906.0            660.5   \n",
      "1   NaN      M    70.7   182.4        10272.0              NaN   \n",
      "2  32.0      F    47.9   174.3         8070.0            861.1   \n",
      "3  25.0      F    68.7   166.6         6597.0              NaN   \n",
      "4  38.0      M     NaN   154.1         4771.0            670.2   \n",
      "\n",
      "   Exercise Minutes  Resting Heart Rate Workout Intensity  Hours of Sleep  \\\n",
      "0              52.0                65.0                lw             9.7   \n",
      "1              39.0                71.0               hgh             7.0   \n",
      "2              46.0                76.0               med             6.4   \n",
      "3              58.0                60.0               med             8.5   \n",
      "4               NaN                73.0                lw             6.7   \n",
      "\n",
      "  Sleep Quality  Stress Level Fitness Goal Achieved  \n",
      "0          Good           5.0                    No  \n",
      "1          Poor           5.0                   Yes  \n",
      "2          Poor           9.0                   Yes  \n",
      "3          Good           5.0                    No  \n",
      "4          Poor           5.0                    No  \n",
      "\n",
      "Dataset info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1030 entries, 0 to 1029\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Age                    972 non-null    float64\n",
      " 1   Gender                 990 non-null    object \n",
      " 2   Weight                 961 non-null    float64\n",
      " 3   Height                 986 non-null    float64\n",
      " 4   Steps per Day          982 non-null    float64\n",
      " 5   Calories Burned        990 non-null    float64\n",
      " 6   Exercise Minutes       983 non-null    float64\n",
      " 7   Resting Heart Rate     983 non-null    float64\n",
      " 8   Workout Intensity      982 non-null    object \n",
      " 9   Hours of Sleep         973 non-null    float64\n",
      " 10  Sleep Quality          988 non-null    object \n",
      " 11  Stress Level           978 non-null    float64\n",
      " 12  Fitness Goal Achieved  980 non-null    object \n",
      "dtypes: float64(9), object(4)\n",
      "memory usage: 104.7+ KB\n",
      "\n",
      "Missing values:\n",
      "Age                      58\n",
      "Gender                   40\n",
      "Weight                   69\n",
      "Height                   44\n",
      "Steps per Day            48\n",
      "Calories Burned          40\n",
      "Exercise Minutes         47\n",
      "Resting Heart Rate       47\n",
      "Workout Intensity        48\n",
      "Hours of Sleep           57\n",
      "Sleep Quality            42\n",
      "Stress Level             52\n",
      "Fitness Goal Achieved    50\n",
      "dtype: int64\n",
      "\n",
      "Data types:\n",
      "Age                      float64\n",
      "Gender                    object\n",
      "Weight                   float64\n",
      "Height                   float64\n",
      "Steps per Day            float64\n",
      "Calories Burned          float64\n",
      "Exercise Minutes         float64\n",
      "Resting Heart Rate       float64\n",
      "Workout Intensity         object\n",
      "Hours of Sleep           float64\n",
      "Sleep Quality             object\n",
      "Stress Level             float64\n",
      "Fitness Goal Achieved     object\n",
      "dtype: object\n",
      "\n",
      "Dataset description:\n",
      "              Age      Weight      Height  Steps per Day  Calories Burned  \\\n",
      "count  972.000000  961.000000  986.000000     982.000000       990.000000   \n",
      "mean    38.787037   70.237357  170.552637    7941.063124       815.850808   \n",
      "std     12.204865   15.894931   10.046059    2959.311043       127.862049   \n",
      "min     18.000000   19.200000  140.700000       0.000000       420.800000   \n",
      "25%     28.000000   59.700000  163.900000    5973.500000       731.075000   \n",
      "50%     40.000000   70.100000  171.000000    7842.500000       813.900000   \n",
      "75%     50.000000   81.400000  177.000000   10000.500000       894.525000   \n",
      "max     59.000000  118.800000  202.600000   18973.000000      1259.700000   \n",
      "\n",
      "       Exercise Minutes  Resting Heart Rate  Hours of Sleep  Stress Level  \n",
      "count        983.000000          983.000000      973.000000    978.000000  \n",
      "mean          51.786368           70.123093        7.004214      4.912065  \n",
      "std           50.287697            9.651678        1.551454      1.960312  \n",
      "min            0.000000           50.000000        1.900000      1.000000  \n",
      "25%           35.000000           64.000000        6.000000      4.000000  \n",
      "50%           47.000000           70.000000        7.000000      5.000000  \n",
      "75%           57.000000           77.000000        8.100000      6.000000  \n",
      "max          675.000000          100.000000       12.300000     10.000000  \n",
      "\n",
      "Number of duplicate rows: 30\n"
     ]
    }
   ],
   "source": [
    "def explore_data(data):\n",
    "    logging.info(\"Exploring data:\")\n",
    "    print(data.head())\n",
    "    print(\"\\nDataset info:\")\n",
    "    data.info()\n",
    "    print(\"\\nMissing values:\")\n",
    "    print(data.isnull().sum())\n",
    "    print(\"\\nData types:\")\n",
    "    print(data.dtypes)\n",
    "    print(\"\\nDataset description:\")\n",
    "    print(data.describe())\n",
    "\n",
    "    duplicate_rows = data.duplicated(\n",
    "        subset=[\n",
    "            \"Age\",\n",
    "            \"Gender\",\n",
    "            \"Height\",\n",
    "            \"Exercise Minutes\",\n",
    "            \"Resting Heart Rate\",\n",
    "        ]\n",
    "    )\n",
    "    print(f\"\\nNumber of duplicate rows: {duplicate_rows.sum()}\")\n",
    "\n",
    "\n",
    "explore_data(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Broken Data Cannot Be Trained On\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset, as it stands, contains several issues:\n",
    "\n",
    "- Missing values in critical fields\n",
    "- Inconsistent data types\n",
    "- Duplicate rows\n",
    "\n",
    "These issues must be resolved before attempting to train a model, as machine learning algorithms require clean, well-structured input data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minimal Data Transformations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform the minimal transformations necessary to allow initial model training. This includes imputing missing values, fixing data types, and converting categorical variables.\n",
    "\n",
    "- [x] Run this code to apply the minimal preprocessing steps:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_preprocessor(numeric_columns, categorical_columns):\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", SimpleImputer(strategy=\"median\"), numeric_columns),\n",
    "            (\n",
    "                \"cat\",\n",
    "                Pipeline(\n",
    "                    [\n",
    "                        (\n",
    "                            \"imputer\",\n",
    "                            SimpleImputer(strategy=\"most_frequent\"),\n",
    "                        ),\n",
    "                        (\n",
    "                            \"encoder\",\n",
    "                            OneHotEncoder(drop=\"first\", sparse_output=False),\n",
    "                        ),\n",
    "                    ]\n",
    "                ),\n",
    "                categorical_columns,\n",
    "            ),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "numeric_columns = [\n",
    "    \"Age\",\n",
    "    \"Weight\",\n",
    "    \"Height\",\n",
    "    \"Steps per Day\",\n",
    "    \"Calories Burned\",\n",
    "    \"Exercise Minutes\",\n",
    "    \"Resting Heart Rate\",\n",
    "    \"Hours of Sleep\",\n",
    "    \"Stress Level\",\n",
    "]\n",
    "categorical_columns = [\"Gender\", \"Workout Intensity\", \"Sleep Quality\"]\n",
    "\n",
    "preprocessor = create_preprocessor(numeric_columns, categorical_columns)\n",
    "\n",
    "X = data.drop(\"Fitness Goal Achieved\", axis=1)\n",
    "y = data[\"Fitness Goal Achieved\"].fillna(\"No\")\n",
    "\n",
    "X_clean_min = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Assess Initial Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the minimally processed data, we can now train a logistic regression model.\n",
    "\n",
    "- [x] Train and assess the initial model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Initial model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.91      0.96      0.94       106\n",
      "         Yes       0.96      0.90      0.93       100\n",
      "\n",
      "    accuracy                           0.93       206\n",
      "   macro avg       0.93      0.93      0.93       206\n",
      "weighted avg       0.93      0.93      0.93       206\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/python/.local/share/virtualenvs/deep_atlas_course-JW55AXv8/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "def train_model(X, y, model_type=\"initial\"):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=42\n",
    "    )\n",
    "    model = LogisticRegression(max_iter=1000, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(f\"\\n{model_type.capitalize()} model performance:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    return model\n",
    "\n",
    "\n",
    "initial_model = train_model(X_clean_min, y, \"initial\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Further Refinements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now further clean and enhance the dataset by removing duplicates, performing feature engineering, and normalizing numeric features.\n",
    "\n",
    "- [x] Perform the refinements:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(data):\n",
    "    data_deduped = data.drop_duplicates(\n",
    "        subset=[\n",
    "            \"Age\",\n",
    "            \"Gender\",\n",
    "            \"Height\",\n",
    "            \"Exercise Minutes\",\n",
    "            \"Resting Heart Rate\",\n",
    "        ]\n",
    "    ).copy()\n",
    "\n",
    "    epsilon = 1e-10\n",
    "    data_deduped[\"Activity Intensity\"] = data_deduped[\"Steps per Day\"] / (\n",
    "        data_deduped[\"Exercise Minutes\"] + epsilon\n",
    "    )\n",
    "    data_deduped[\"Sleep Efficiency\"] = np.where(\n",
    "        data_deduped[\"Sleep Quality\"] == \"Good\",\n",
    "        data_deduped[\"Hours of Sleep\"] * 1.5,\n",
    "        data_deduped[\"Hours of Sleep\"],\n",
    "    )\n",
    "    data_deduped[\"Calories per Step\"] = data_deduped[\"Calories Burned\"] / (\n",
    "        data_deduped[\"Steps per Day\"] + epsilon\n",
    "    )\n",
    "\n",
    "    data_deduped = data_deduped.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    numeric_columns = data_deduped.select_dtypes(\n",
    "        include=[np.number]\n",
    "    ).columns\n",
    "    categorical_columns = data_deduped.select_dtypes(\n",
    "        exclude=[np.number]\n",
    "    ).columns\n",
    "\n",
    "    data_deduped[numeric_columns] = data_deduped[numeric_columns].fillna(\n",
    "        data_deduped[numeric_columns].median()\n",
    "    )\n",
    "    for col in categorical_columns:\n",
    "        data_deduped[col] = data_deduped[col].fillna(\n",
    "            data_deduped[col].mode()[0]\n",
    "        )\n",
    "\n",
    "    return data_deduped\n",
    "\n",
    "\n",
    "data_preprocessed = preprocess_data(data)\n",
    "\n",
    "X_final = data_preprocessed.drop(\n",
    "    [\n",
    "        \"Fitness Goal Achieved\",\n",
    "        \"Gender\",\n",
    "        \"Workout Intensity\",\n",
    "        \"Sleep Quality\",\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "y_final = data_preprocessed[\"Fitness Goal Achieved\"].fillna(\"No\")\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Assess Final Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will train a second logistic regression model using the fully processed dataset and compare its performance to the initial model.\n",
    "\n",
    "- [ ] Train and assess the final model:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Final model performance:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          No       0.95      0.97      0.96       104\n",
      "         Yes       0.97      0.95      0.96        96\n",
      "\n",
      "    accuracy                           0.96       200\n",
      "   macro avg       0.96      0.96      0.96       200\n",
      "weighted avg       0.96      0.96      0.96       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_model = train_model(X_scaled, y_final, \"final\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ðŸš¦ Checkpoint: Stop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [x] Complete the feedback form and run the following cell to log your stop time:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_atlas.log_feedback(\n",
    "#     {\n",
    "#         # How long were you actively focused on this section? (HH:MM)\n",
    "#         \"active_time\": 00:20,\n",
    "#         # Did you feel finished with this section (Yes/No):\n",
    "#         \"finished\": yes,\n",
    "#         # How much did you enjoy this section? (1â€“5)\n",
    "#         \"enjoyment\": 4,\n",
    "#         # How useful was this section? (1â€“5)\n",
    "#         \"usefulness\": 4,\n",
    "#         # Did you skip any steps?\n",
    "#         \"skipped_steps\": no,\n",
    "#         # Any obvious opportunities for improvement?\n",
    "#         \"suggestions\": [],\n",
    "#     }\n",
    "# )\n",
    "# deep_atlas.log_stop_time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You Did It!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you successfully:\n",
    "\n",
    "- Loaded a broken dataset.\n",
    "- Identified and addressed issues like missing values and incorrect data types.\n",
    "- Trained an initial model with minimal data transformations.\n",
    "- Performed further refinements like feature engineering and normalization.\n",
    "- Compared the performance of models trained on minimally processed and fully processed data.\n",
    "\n",
    "This exercise demonstrates the importance of thorough data preprocessing and its impact on model performance. Well done!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Coursework-khinsGju",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
